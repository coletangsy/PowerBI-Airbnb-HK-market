{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from string import punctuation\r\n",
    "import csv\r\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# export to csv file\r\n",
    "def export_cols_dtype_to_csv(filename):\r\n",
    "    df = pd.read_csv(f\"{filename}\")\r\n",
    "    filename_df = pd.DataFrame(df.dtypes).reset_index().rename(columns={\"index\":\"column\", 0:\"dtype\"})\r\n",
    "    filename = filename.replace(\".csv\",\"\")\r\n",
    "    with open(f\"{filename}_cols_info.csv\", mode=\"w\") as csv_writer:\r\n",
    "        csv_writer.write(filename_df.to_csv(line_terminator=\"\\n\", index=False))\r\n",
    "\r\n",
    "export_cols_dtype_to_csv(filename=\"listings.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "pd.read_csv(\"listing_cols_info.csv\").head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        column   dtype\n",
       "0           id   int64\n",
       "1  listing_url  object\n",
       "2    scrape_id   int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>listing_url</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scrape_id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "stops = list(stopwords.words(\"english\"))\r\n",
    "punct = list(punctuation)\r\n",
    "\r\n",
    "# words = \"hello, i am Isaac\"\r\n",
    "# words = word_tokenize(words)\r\n",
    "# new_word = []\r\n",
    "# for w in words:\r\n",
    "#     if w not in stops and w not in punct:\r\n",
    "#         new_word.append(w)\r\n",
    "# new_word "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "# reviews_df = pd.read_csv(\"reviews.csv\", encoding=\"utf_8\")\r\n",
    "# comments = list(reviews_df[\"comments\"].values)\r\n",
    "# comments[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Lovely apartment in a great location that quickly felt like home. It is always much more pleasant to return to homey apt than an anonymous hotel room. Amy is also quick to respond and a pleasure to correspond with.',\n",
       " 'As a former resident of HK, I can say that Amy\\'s flat is really a great flat that is a great example of Hong Kong homes in this area.  The neighborhood is very convenient for visitors to HK and also has a lot of charm and history (steps away from the British landing spot for colonial HK).\\r<br/>\\r<br/>And I must mention that Amy was a great \"non-present\" host as she has thought of everything and made a lot of provisions for the comfort of guests that would not have been included or even thought of by others.  Not to mention that the apartment is spotless and well kept.  ',\n",
       " 'I stayed in this Apt for about 12 days. Such an amazing place. Right in the heart of everything. I had no problems or issues whatsoever. Amy even went out of her way to get a few misc items before my arrival. Will definitely looking into staying in this apartment again. Thanks for an incredible stay in Hong Kong! \\r<br/>\\r<br/>']"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "# # for com in comments[-1]:\r\n",
    "# #     print(word_tokenize([\"?????????\"]))\r\n",
    "# www= \"aaaaa,br/,/br/\"\r\n",
    "# # www[:-5]\r\n",
    "# if \",br/,/br/\" in www:\r\n",
    "#     www = www[:-5]\r\n",
    "#     print(www)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aaaaa,br/\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "# def tokenize(csv_file):\r\n",
    "reviews_df = pd.read_csv(\"reviews.csv\", encoding=\"utf_8\")\r\n",
    "comments = list(reviews_df[\"comments\"].values)\r\n",
    "\r\n",
    "new_comments = []\r\n",
    "for com in comments:\r\n",
    "    if type(com) == float:\r\n",
    "        com = \"blank\"\r\n",
    "    com = com.replace(\"\\r<br/>\",\"\")\r\n",
    "    try:\r\n",
    "        new_com = word_tokenize(com)\r\n",
    "    except TypeError:\r\n",
    "        new_com = \"blank\"\r\n",
    "\r\n",
    "    token = \",\".join([word for word in new_com if (word not in stops and word not in punct)])\r\n",
    "    if len(token) <= 1:\r\n",
    "        token = \"blank\"\r\n",
    "    new_comments.append(token)\r\n",
    "\r\n",
    "new_comments[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Lovely,apartment,great,location,quickly,felt,like,home,It,always,much,pleasant,return,homey,apt,anonymous,hotel,room,Amy,also,quick,respond,pleasure,correspond',\n",
       " \"As,former,resident,HK,I,say,Amy,'s,flat,really,great,flat,great,example,Hong,Kong,homes,area,The,neighborhood,convenient,visitors,HK,also,lot,charm,history,steps,away,British,landing,spot,colonial,HK,.And,I,must,mention,Amy,great,``,non-present,'',host,thought,everything,made,lot,provisions,comfort,guests,would,included,even,thought,others,Not,mention,apartment,spotless,well,kept\",\n",
       " 'I,stayed,Apt,12,days,Such,amazing,place,Right,heart,everything,I,problems,issues,whatsoever,Amy,even,went,way,get,misc,items,arrival,Will,definitely,looking,staying,apartment,Thanks,incredible,stay,Hong,Kong']"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "reviews_df[\"token\"] = new_comments\r\n",
    "reviews_df.head(4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   listing_id      id        date  reviewer_id reviewer_name  \\\n",
       "0       69074  181973  2011-02-14       358597       Chi Yan   \n",
       "1       69074  252237  2011-05-05       467243        Doreen   \n",
       "2       69074  400484  2011-07-27       696753       Michael   \n",
       "3       69074  411022  2011-08-01        40901         Donna   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Lovely apartment in a great location that quic...   \n",
       "1  As a former resident of HK, I can say that Amy...   \n",
       "2  I stayed in this Apt for about 12 days. Such a...   \n",
       "3  Amy's cute, comfortable apartment is in the he...   \n",
       "\n",
       "                                               token  \n",
       "0  Lovely,apartment,great,location,quickly,felt,l...  \n",
       "1  As,former,resident,HK,I,say,Amy,'s,flat,really...  \n",
       "2  I,stayed,Apt,12,days,Such,amazing,place,Right,...  \n",
       "3  Amy,'s,cute,comfortable,apartment,heart,Sheung...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69074</td>\n",
       "      <td>181973</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>358597</td>\n",
       "      <td>Chi Yan</td>\n",
       "      <td>Lovely apartment in a great location that quic...</td>\n",
       "      <td>Lovely,apartment,great,location,quickly,felt,l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69074</td>\n",
       "      <td>252237</td>\n",
       "      <td>2011-05-05</td>\n",
       "      <td>467243</td>\n",
       "      <td>Doreen</td>\n",
       "      <td>As a former resident of HK, I can say that Amy...</td>\n",
       "      <td>As,former,resident,HK,I,say,Amy,'s,flat,really...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69074</td>\n",
       "      <td>400484</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>696753</td>\n",
       "      <td>Michael</td>\n",
       "      <td>I stayed in this Apt for about 12 days. Such a...</td>\n",
       "      <td>I,stayed,Apt,12,days,Such,amazing,place,Right,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69074</td>\n",
       "      <td>411022</td>\n",
       "      <td>2011-08-01</td>\n",
       "      <td>40901</td>\n",
       "      <td>Donna</td>\n",
       "      <td>Amy's cute, comfortable apartment is in the he...</td>\n",
       "      <td>Amy,'s,cute,comfortable,apartment,heart,Sheung...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "source": [
    "reviews_df['comments'].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "metadata": {},
     "execution_count": 263
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "source": [
    "reviews_df['comments'] = reviews_df['comments'].fillna(\"blank\")\r\n",
    "reviews_df['comments'].isna().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 264
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "source": [
    "rere = 'Lovely apartment in a great location that quickly felt like home. It is always much more pleasant to return to homey apt than an anonymous hotel room. Amy is also quick to respond and a pleasure to correspond with.'\r\n",
    "sia.polarity_scores(rere)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.644, 'pos': 0.356, 'compound': 0.9565}"
      ]
     },
     "metadata": {},
     "execution_count": 271
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "source": [
    "def sentiment_analyzer(review_col):\r\n",
    "    \"\"\"\r\n",
    "    input the review series, output a new series named 'summary_sentiment' in where 'positive / neutral / negative'\r\n",
    "    \"\"\"\r\n",
    "    summary_sentiment = []\r\n",
    "    sia = SentimentIntensityAnalyzer()\r\n",
    "    for comment in review_col:\r\n",
    "        ss = sia.polarity_scores(comment)\r\n",
    "        compound = ss['compound']\r\n",
    "\r\n",
    "        if compound >= 0.03:\r\n",
    "            summary_sentiment.append('positive')\r\n",
    "        elif (compound > -0.1) and (compound < 0.03):\r\n",
    "            summary_sentiment.append('neutral')\r\n",
    "        else:\r\n",
    "            summary_sentiment.append('negative')\r\n",
    "\r\n",
    "    return summary_sentiment\r\n",
    "\r\n",
    "reviews_df[\"sentiment\"] = sentiment_analyzer(reviews_df[\"comments\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "source": [
    "with open(\"reviews_add_token.csv\", \"w\", encoding=\"utf-8-sig\") as csv_token_writer:\r\n",
    "    csv_token_writer.write(reviews_df.to_csv(line_terminator=\"\\n\", index=False).replace(\"\\r<br/>\",\"\"))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "2e7bd34cf8adaff6fe39da52b2b333248e2f4a424e35a69aad602b99d1bfe04e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}